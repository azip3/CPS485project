# CPS485project

## Description
(Basic Proposal/subject to change)
My project idea is a live ASL gesture recognition application. It would use a Convolutional Neural Network  to classify American Sign Language hand gestures from webcam video input. The system would detect hand landmarks, processes frames, and displays the predicted sign in real time.

Key features:
- Real-time gesture detection via webcam
- Trained neural network for high-accuracy classification
- User-friendly interface for live demonstration
- Possible visualization of training progress (loss/accuracy curves)